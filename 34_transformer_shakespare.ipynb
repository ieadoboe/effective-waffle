{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is All You Need\n",
    "\n",
    "Coding a transformer from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Shakespeares work from Andrej Karpathy's website\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt', url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the first few characters\n",
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in vocabulary: 65\n",
      "Total length of text dataset: 1115394\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(set(shakespeare_text))\n",
    "char_to_int = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "# How many number of distinct characters has the vocabulary:\n",
    "tokens_len = len(unique_chars)\n",
    "print(f'Number of tokens in vocabulary: {tokens_len}')\n",
    "\n",
    "# How many characters has the dataset:\n",
    "text_length = len(shakespeare_text)\n",
    "print(f'Total length of text dataset: {text_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "(1, 1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_59 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> (2.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m650\u001b[0m (2.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> (2.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m650\u001b[0m (2.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(tokens_len, embedding_dim))\n",
    "\n",
    "input_array = np.random.randint(tokens_len, size=(1, 1))\n",
    "model.compile('rmsprop', 'sparse_categorical_crossentropy')\n",
    "\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)\n",
    "\n",
    "model.summary()\n",
    "# (1, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_pos_enc, embedding_dim, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.max_len = max_pos_enc # maximum sequence length that the model can handle\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Create the positional encodings\n",
    "        position = np.arange(max_pos_enc)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
    "        pe = np.zeros((max_pos_enc, embedding_dim))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        \n",
    "        # Add batch dimension e.g. (max_pos_enc,embedding_dim) -> (1,max_pos_enc,embedding_dim)\n",
    "        self.pe = tf.constant(pe[np.newaxis, :, :], dtype=tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]  # Get sequence length from input\n",
    "        return inputs + self.pe[:, :seq_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 10  # Embedding dimension\n",
    "max_len = 50  # Maximum sequence length\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokens_len, embedding_dim),\n",
    "    PositionalEncoding(max_len, embedding_dim)\n",
    "])\n",
    "\n",
    "input_array = np.random.randint(tokens_len, size=(1, 10))  # Example input\n",
    "output_array = model(input_array)\n",
    "\n",
    "print(output_array.shape)  # Should be (1, 10, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding_56          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_60 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)            │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding_56          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> (2.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m650\u001b[0m (2.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> (2.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m650\u001b[0m (2.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        q, k, v = inputs\n",
    "        \n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        \n",
    "        # dot product attention\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True) # (bs, q_len, k_len)\n",
    "        \n",
    "        # scale dot product\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        \n",
    "        # apply mask when necessary\n",
    "        if mask is not None:\n",
    "            # adding very large negative values \n",
    "            # so they go to zero after softmax\n",
    "            scaled_attention_logits += (mask * -1e9) \n",
    "        \n",
    "        # apply softmax to attention weights (scores)\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        \n",
    "        # multiply by V (values)\n",
    "        out = tf.matmul(attention_weights, v)\n",
    "        \n",
    "        return out, attention_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Head Attention Head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, embedding_dim, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dim = embedding_dim\n",
    "        assert embedding_dim % num_heads == 0, \"embedding_dim must be divisible by num_heads\"\n",
    "        self.depth = embedding_dim // num_heads # depth per head\n",
    "        \n",
    "        # linear projection layers\n",
    "        self.wq = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.wk = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.wv = tf.keras.layers.Dense(embedding_dim)\n",
    "        \n",
    "        # output projection\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        \n",
    "        self.attention = ScaledDotProductAttention()\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        q, k, v = inputs\n",
    "        \n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        # linear projections\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        # reshaping q, k, v\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        scaled_attention, attention_weights = self.attention([q, k, v], mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        \n",
    "        out = self.dense(concat_attention)\n",
    "        \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Network\n",
    "\n",
    "$$\\text{FFN(x)} = \\text{max}(0,~ xW_1 + b_1)W_2 + b_2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, hidden_dim, **kwargs):\n",
    "        super(PositionwiseFeedForward, self).__init__(**kwargs)\n",
    "        \n",
    "        # hidden_dim (dff) - feed forward network hidden \n",
    "        # layer dimension a.k.a inner layer dimensionality\n",
    "        \n",
    "        self.dense1 = tf.keras.layers.Dense(hidden_dim, activation=\"relu\")\n",
    "        self.dense2 = tf.keras.layers.Dense(embedding_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.dense1(inputs)\n",
    "        \n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_heads, dropout_rate = 0.1, **kwargs):\n",
    "        super(EncoderLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.mha = MultiHeadAttention(num_heads, embedding_dim)\n",
    "        self.ffn = PositionwiseFeedForward(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        \n",
    "        # multi-head attention\n",
    "        attention_output, _ = self.mha([inputs, inputs, inputs], mask)\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        out1 = self.layer_norm1(inputs + attention_output)\n",
    "        \n",
    "        # feed-forward network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layer_norm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The Encoder stacks multiple encoder layer to create the full encoder. It includes the Embedding layer and Positional Encoding layer as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dim, hidden_dim, num_heads, \n",
    "                 tokens_len, max_pos_enc, dropout_rate=0.1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "            \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(tokens_len, embedding_dim)\n",
    "        self.pos_encoding = PositionalEncoding(max_pos_enc, embedding_dim)\n",
    "        \n",
    "        self.encoding_layers = [\n",
    "            EncoderLayer(embedding_dim, hidden_dim, num_heads, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        \n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoding_layers[i](x, training, mask)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        super(DecoderLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        # Self-attention\n",
    "        self.self_attention = MultiHeadAttention(num_heads, embedding_dim)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # Cross-attention (encoder-decoder attention)\n",
    "        self.cross_attention = MultiHeadAttention(num_heads, embedding_dim)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ffn = PositionwiseFeedForward(embedding_dim, hidden_dim)\n",
    "        self.norm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, inputs, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n",
    "        # Self attention with look-ahead mask\n",
    "        self_attn_output, _ = self.self_attention([inputs, inputs, inputs], look_ahead_mask)\n",
    "        self_attn_output = self.dropout1(self_attn_output, training=training)\n",
    "        out1 = self.norm1(inputs + self_attn_output)\n",
    "        \n",
    "        # Cross attention with encoder output\n",
    "        cross_attn_output, _ = self.cross_attention([out1, enc_output, enc_output], padding_mask)\n",
    "        cross_attn_output = self.dropout2(cross_attn_output, training=training)\n",
    "        out2 = self.norm2(out1 + cross_attn_output)\n",
    "        \n",
    "        # Feed forward\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.norm3(out2 + ffn_output)\n",
    "        \n",
    "        return out3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dim, hidden_dim, num_heads,\n",
    "                 tokens_len, max_pos_enc, dropout_rate=0.1, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(tokens_len, embedding_dim)\n",
    "        self.pos_encoding = PositionalEncoding(max_pos_enc, embedding_dim)\n",
    "        \n",
    "        self.decoder_layers = [\n",
    "            DecoderLayer(embedding_dim, hidden_dim, num_heads, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # embedding and positional encoding\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        # decoder layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.decoder_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, embedding_dim, hidden_dim, num_heads,\n",
    "                 input_vocab_size, target_vocab_size, max_pos_enc,\n",
    "                 dropout_rate=0.1, **kwargs):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            num_layers, embedding_dim, hidden_dim, num_heads,\n",
    "            input_vocab_size, max_pos_enc, dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "            num_layers, embedding_dim, hidden_dim, num_heads,\n",
    "            target_vocab_size, max_pos_enc, dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def create_padding_mask(self, seq):\n",
    "        \"\"\"Creates a mask for padding tokens (value 0)\"\"\"\n",
    "        seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "        return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "    \n",
    "    def create_look_ahead_mask(self, seq_len):\n",
    "        \"\"\"Creates a mask to prevent attention to future tokens\"\"\"\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        return mask  # (seq_len, seq_len)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        inp, tar = inputs\n",
    "        \n",
    "        # Create masks\n",
    "        enc_padding_mask = self.create_padding_mask(inp)\n",
    "        dec_padding_mask = self.create_padding_mask(inp)\n",
    "        \n",
    "        # Look ahead mask for decoder\n",
    "        look_ahead_mask = self.create_look_ahead_mask(tf.shape(tar)[1])\n",
    "        dec_target_padding_mask = self.create_padding_mask(tar)\n",
    "        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        \n",
    "        # Encoder output\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "        \n",
    "        # Decoder output\n",
    "        dec_output = self.decoder(\n",
    "            tar, enc_output, training, combined_mask, dec_padding_mask\n",
    "        )\n",
    "        \n",
    "        # Final output\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1031 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_33 (\u001b[38;5;33mEncoder\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_27 (\u001b[38;5;33mDecoder\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1031 (\u001b[38;5;33mDense\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example parameters\n",
    "    num_layers = 4\n",
    "    embedding_dim = 512\n",
    "    hidden_dim = 2048\n",
    "    num_heads = 8\n",
    "    input_vocab_size = 8000\n",
    "    target_vocab_size = 8000\n",
    "    max_pos_enc = 10000\n",
    "    dropout_rate = 0.1\n",
    "    \n",
    "    # Create model\n",
    "    transformer = Transformer(\n",
    "        num_layers, embedding_dim, hidden_dim, num_heads,\n",
    "        input_vocab_size, target_vocab_size, max_pos_enc, dropout_rate\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    transformer.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Print model summary\n",
    "    print(transformer.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/keras/src/layers/layer.py:1381: UserWarning: Layer 'transformer_34' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)''\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_34', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Transformer.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Transformer.call():\n  • inputs=['tf.Tensor(shape=(1, 4), dtype=int32)', 'tf.Tensor(shape=(1, 1), dtype=int32)']\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[280], line 113\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Generate text with the untrained model\u001b[39;00m\n\u001b[1;32m    112\u001b[0m seed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello world\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 113\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_untrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated text from untrained model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_text)\n",
      "Cell \u001b[0;32mIn[280], line 33\u001b[0m, in \u001b[0;36mgenerate_text_untrained\u001b[0;34m(model, tokenizer, start_string, max_length, temperature)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Generate one token at a time\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Predictions shape: (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# We want the prediction for the last token in the sequence\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# (batch_size, vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[273], line 42\u001b[0m, in \u001b[0;36mTransformer.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     39\u001b[0m combined_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmaximum(dec_target_padding_mask, look_ahead_mask)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Encoder output\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m enc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Decoder output\u001b[39;00m\n\u001b[1;32m     45\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m     46\u001b[0m     tar, enc_output, training, combined_mask, dec_padding_mask\n\u001b[1;32m     47\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Transformer.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Transformer.call():\n  • inputs=['tf.Tensor(shape=(1, 4), dtype=int32)', 'tf.Tensor(shape=(1, 1), dtype=int32)']\n  • training=False"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you've already defined your Transformer class from the previous code\n",
    "# This example shows how to generate text with an untrained model\n",
    "\n",
    "def generate_text_untrained(model, tokenizer, start_string, max_length=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate text using an untrained transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model: The untrained transformer model\n",
    "        tokenizer: A tokenizer to convert between text and token IDs\n",
    "        start_string: The initial seed text\n",
    "        max_length: Maximum length of the generated text\n",
    "        temperature: Controls randomness (higher = more random)\n",
    "    \n",
    "    Returns:\n",
    "        The generated text\n",
    "    \"\"\"\n",
    "    # Convert start string to tokens\n",
    "    input_tokens = tokenizer.encode(start_string)\n",
    "    input_tensor = tf.convert_to_tensor([input_tokens], dtype=tf.int32)\n",
    "    \n",
    "    # Create an empty target sequence with just the start token\n",
    "    target_tensor = tf.convert_to_tensor([[tokenizer.token_to_id('<start>')]], dtype=tf.int32)\n",
    "    \n",
    "    generated_text = start_string\n",
    "    \n",
    "    # Generate one token at a time\n",
    "    for i in range(max_length):\n",
    "        # Get predictions\n",
    "        predictions = model([input_tensor, target_tensor], training=False)\n",
    "        \n",
    "        # Predictions shape: (batch_size, seq_len, vocab_size)\n",
    "        # We want the prediction for the last token in the sequence\n",
    "        predictions = predictions[:, -1, :]  # (batch_size, vocab_size)\n",
    "        \n",
    "        # Apply temperature\n",
    "        predictions = predictions / temperature\n",
    "        \n",
    "        # Sample from the distribution\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[0, 0].numpy()\n",
    "        \n",
    "        # Break if we predict the end token\n",
    "        if predicted_id == tokenizer.token_to_id('<end>'):\n",
    "            break\n",
    "            \n",
    "        # Convert the predicted token ID to text\n",
    "        predicted_word = tokenizer.id_to_token(predicted_id)\n",
    "        generated_text += \" \" + predicted_word\n",
    "        \n",
    "        # Update the target tensor\n",
    "        new_target = tf.concat([target_tensor, [[predicted_id]]], axis=-1)\n",
    "        target_tensor = new_target\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a simple tokenizer for demonstration\n",
    "    # In a real application, you'd use a proper tokenizer\n",
    "    class SimpleTokenizer:\n",
    "        def __init__(self, vocab_size=1000):\n",
    "            self.vocab_size = vocab_size\n",
    "            # This would normally be a real vocabulary\n",
    "            self.special_tokens = {\n",
    "                '<start>': 0,\n",
    "                '<end>': 1,\n",
    "                '<pad>': 2,\n",
    "                '<unk>': 3\n",
    "            }\n",
    "            \n",
    "        def token_to_id(self, token):\n",
    "            if token in self.special_tokens:\n",
    "                return self.special_tokens[token]\n",
    "            # For demonstration, just return a random ID\n",
    "            return np.random.randint(4, self.vocab_size)\n",
    "            \n",
    "        def id_to_token(self, id):\n",
    "            for token, token_id in self.special_tokens.items():\n",
    "                if id == token_id:\n",
    "                    return token\n",
    "            # For demonstration, just return a placeholder\n",
    "            return f\"word_{id}\"\n",
    "            \n",
    "        def encode(self, text):\n",
    "            # For demonstration, return some random IDs\n",
    "            return [self.special_tokens['<start>']] + [self.token_to_id(t) for t in text.split()] + [self.special_tokens['<end>']]\n",
    "    \n",
    "    \n",
    "    # Parameters\n",
    "    num_layers = 2\n",
    "    embedding_dim = 64\n",
    "    hidden_dim = 128\n",
    "    num_heads = 4\n",
    "    input_vocab_size = 1000\n",
    "    target_vocab_size = 1000\n",
    "    max_pos_enc = 100\n",
    "    \n",
    "    # Create model (untrained)\n",
    "    transformer = Transformer(\n",
    "        num_layers, embedding_dim, hidden_dim, num_heads,\n",
    "        input_vocab_size, target_vocab_size, max_pos_enc\n",
    "    )\n",
    "    \n",
    "    # Create simple tokenizer\n",
    "    tokenizer = SimpleTokenizer(vocab_size=input_vocab_size)\n",
    "    \n",
    "    # Generate text with the untrained model\n",
    "    seed_text = \"hello world\"\n",
    "    generated_text = generate_text_untrained(\n",
    "        transformer, tokenizer, seed_text, max_length=20, temperature=1.2\n",
    "    )\n",
    "    \n",
    "    print(\"Generated text from untrained model:\")\n",
    "    print(generated_text)\n",
    "    print(\"\\nNote: This text is random and doesn't make sense because the model is untrained.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
