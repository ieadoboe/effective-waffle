{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the Shakespeare text\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt', url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character-level tokenization\n",
    "vocab = sorted(set(shakespeare_text))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'First 100 characters of text: {shakespeare_text[:100]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "d_model = 256  # Embedding dimension\n",
    "num_heads = 8  # Number of attention heads\n",
    "dff = 512  # Feed-forward network dimension\n",
    "max_seq_length = 100  # Maximum sequence length\n",
    "batch_size = 64  # Batch size\n",
    "dropout_rate = 0.1  # Dropout rate\n",
    "num_layers = 4  # Number of encoder and decoder layers\n",
    "learning_rate = 0.0001  # Learning rate\n",
    "epochs = 30  # Number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "def text_to_indices(text):\n",
    "    return [char_to_idx[char] for char in text]\n",
    "\n",
    "def indices_to_text(indices):\n",
    "    return ''.join([idx_to_char[idx] for idx in indices])\n",
    "\n",
    "def create_training_data(text, seq_length=100, batch_size=64):\n",
    "    text_as_indices = text_to_indices(text)\n",
    "    total_seq = len(text_as_indices) - seq_length\n",
    "    \n",
    "    # Convert to numpy array for efficient indexing\n",
    "    text_as_indices_np = np.array(text_as_indices)\n",
    "    \n",
    "    # Create input and target sequences\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "    for i in range(0, total_seq, seq_length // 4):  # Use stride for more efficient data usage\n",
    "        if i + seq_length >= total_seq:\n",
    "            break\n",
    "        input_seqs.append(text_as_indices_np[i:i+seq_length])\n",
    "        target_seqs.append(text_as_indices_np[i+1:i+seq_length+1])\n",
    "    \n",
    "    # Convert to TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_seqs, target_seqs))\n",
    "    \n",
    "    # Batch and shuffle\n",
    "    dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_training_data(shakespeare_text, seq_length=max_seq_length, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def get_positional_encoding(max_seq_len, d_model):\n",
    "    position = np.arange(max_seq_len)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "    \n",
    "    pos_encoding = np.zeros((max_seq_len, d_model))\n",
    "    pos_encoding[:, 0::2] = np.sin(position * div_term)\n",
    "    pos_encoding[:, 1::2] = np.cos(position * div_term)\n",
    "    \n",
    "    return tf.cast(pos_encoding[np.newaxis, ...], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Dot-Product Attention\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    # Calculate attention scores\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    \n",
    "    # Scale attention scores\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    # Apply mask (if provided)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    # Calculate attention weights\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    \n",
    "    # Apply attention weights to value vectors\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-wise Feed-Forward Network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask=None):\n",
    "        attn_output, _ = self.mha(v=x, k=x, q=x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "            look_ahead_mask=None, padding_mask=None):\n",
    "        # Masked multi-head attention (self-attention)\n",
    "        attn1, attn_weights_block1 = self.mha1(v=x, k=x, q=x, mask=look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        # Multi-head attention (encoder-decoder attention)\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            v=enc_output, k=enc_output, q=out1, mask=padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                maximum_position_encoding, rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = get_positional_encoding(maximum_position_encoding, d_model)\n",
    "        \n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff, rate) \n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # Positional encoding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        # Encoder layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x=x, training=training, mask=mask)\n",
    "        \n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                maximum_position_encoding, rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = get_positional_encoding(maximum_position_encoding, d_model)\n",
    "        \n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model, num_heads, dff, rate) \n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, \n",
    "            look_ahead_mask=None, padding_mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # Positional encoding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        # Decoder layers\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](\n",
    "                x=x, \n",
    "                enc_output=enc_output, \n",
    "                training=training,\n",
    "                look_ahead_mask=look_ahead_mask, \n",
    "                padding_mask=padding_mask)\n",
    "            \n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "        \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create look-ahead mask for decoder\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "                target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                                input_vocab_size, pe_input, rate)\n",
    "        \n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                                target_vocab_size, pe_target, rate)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self, inp, tar, training, enc_padding_mask=None, \n",
    "            look_ahead_mask=None, dec_padding_mask=None):\n",
    "        # Encoder\n",
    "        enc_output = self.encoder(x=inp, training=training, mask=enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "        \n",
    "        # Decoder\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            x=tar, \n",
    "            enc_output=enc_output, \n",
    "            training=training, \n",
    "            look_ahead_mask=look_ahead_mask, \n",
    "            padding_mask=dec_padding_mask)\n",
    "        \n",
    "        # Final linear layer\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        \n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transformer model\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=vocab_size,\n",
    "    target_vocab_size=vocab_size,\n",
    "    pe_input=max_seq_length,\n",
    "    pe_target=max_seq_length,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "# Loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "# Initialize metrics for tracking loss and accuracy\n",
    "class TrainingMetrics:\n",
    "    def __init__(self):\n",
    "        self._loss_values = []\n",
    "        self._accuracy_values = []\n",
    "        \n",
    "    def update_loss(self, loss):\n",
    "        self._loss_values.append(float(loss))\n",
    "        \n",
    "    def update_accuracy(self, real, pred):\n",
    "        # Calculate accuracy from sparse categorical data\n",
    "        predictions = tf.argmax(pred, axis=-1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(real, predictions), tf.float32))\n",
    "        self._accuracy_values.append(float(accuracy))\n",
    "        \n",
    "    def result_loss(self):\n",
    "        return sum(self._loss_values) / max(len(self._loss_values), 1)\n",
    "        \n",
    "    def result_accuracy(self):\n",
    "        return sum(self._accuracy_values) / max(len(self._accuracy_values), 1)\n",
    "        \n",
    "    def reset(self):\n",
    "        self._loss_values = []\n",
    "        self._accuracy_values = []\n",
    "\n",
    "# Create training metrics\n",
    "train_metrics = TrainingMetrics()\n",
    "\n",
    "# Training step\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp=inp, \n",
    "            tar=tar_inp, \n",
    "            training=True, \n",
    "            enc_padding_mask=None, \n",
    "            look_ahead_mask=look_ahead_mask, \n",
    "            dec_padding_mask=None\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    return loss, tar_real, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "def generate_text(model, start_string, num_generate=1000, temperature=1.0):\n",
    "    # Convert start string to indices\n",
    "    input_indices = text_to_indices(start_string)\n",
    "    input_tensor = tf.expand_dims(input_indices, 0)\n",
    "    \n",
    "    # Empty result string\n",
    "    result = start_string\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        # Create look-ahead mask\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(input_tensor)[1])\n",
    "        \n",
    "        # Call model with keyword arguments\n",
    "        output, _ = model(\n",
    "            inp=input_tensor, \n",
    "            tar=input_tensor, \n",
    "            training=False, \n",
    "            enc_padding_mask=None,\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            dec_padding_mask=None\n",
    "        )\n",
    "        \n",
    "        # Select the last token from the output\n",
    "        output = output[:, -1, :]  # (batch_size, vocab_size)\n",
    "        \n",
    "        # Apply temperature\n",
    "        if temperature != 1.0:\n",
    "            output = output / temperature\n",
    "        \n",
    "        # Sample from the output distribution\n",
    "        predicted_id = tf.random.categorical(output, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        # Concatenate the predicted character to the output text\n",
    "        result += idx_to_char[predicted_id]\n",
    "        \n",
    "        # Update the input tensor to the decoder\n",
    "        input_indices.append(predicted_id)\n",
    "        input_tensor = tf.expand_dims(input_indices[-max_seq_length:], 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text before training\n",
    "print(\"\\n----- Text generated before training -----\\n\")\n",
    "start_string = \"ROMEO: \"\n",
    "generated_text = generate_text(transformer, start_string, num_generate=250, temperature=1.0)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n",
      "First 100 characters of text: First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "----- Text generated before training -----\n",
      "\n",
      "ROMEO: ttuPgaoPQ?.SD'bZIuhnh3OQZIZhh?LLg.FlchhPZghqYd;YbA;uQTM!.YgYtXgwgbFgQL DwgqgSgRh lCI.Clhhc!tPg?a;Hc::PijVgqBBuSQgcZZX!,gcc$V gMIehBSIZ'SZZZgZ-ggahgPZRacuOlxDQBZFqZZKHBZFt:MkxKcPStZ;tBq;ZBhVchgsSQ;SgIgIZ:iB:Lg.;uh:CLBZzQZhbVIghZZ B:;yXgclZhzhq\n",
      ";!lxhq$\n",
      "Epoch 1 Batch 0 Loss 4.6906 Accuracy 0.0074\n",
      "Epoch 1 Batch 50 Loss 3.4642 Accuracy 0.1284\n",
      "Epoch 1 Batch 100 Loss 3.3923 Accuracy 0.1373\n",
      "Epoch 1 Batch 150 Loss 3.3656 Accuracy 0.1415\n",
      "Epoch 1 Batch 200 Loss 3.3491 Accuracy 0.1443\n",
      "Epoch 1 Batch 250 Loss 3.3378 Accuracy 0.1461\n",
      "Epoch 1 Batch 300 Loss 3.3305 Accuracy 0.1474\n",
      "Epoch 1 Batch 350 Loss 3.3242 Accuracy 0.1482\n",
      "Epoch 1 Batch 400 Loss 3.3184 Accuracy 0.1487\n",
      "Epoch 1 Batch 450 Loss 3.3142 Accuracy 0.1492\n",
      "Epoch 1 Batch 500 Loss 3.3102 Accuracy 0.1496\n",
      "Epoch 1 Batch 550 Loss 3.3074 Accuracy 0.1499\n",
      "Epoch 1 Batch 600 Loss 3.3056 Accuracy 0.1500\n",
      "Epoch 1 Batch 650 Loss 3.3043 Accuracy 0.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:11:09.298152: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.3032 Accuracy 0.1502\n",
      "Time taken for 1 epoch: 1181.80 secs\n",
      "Epoch 2 Batch 0 Loss 3.3221 Accuracy 0.1461\n",
      "Epoch 2 Batch 50 Loss 3.2900 Accuracy 0.1492\n",
      "Epoch 2 Batch 100 Loss 3.2872 Accuracy 0.1499\n",
      "Epoch 2 Batch 150 Loss 3.2871 Accuracy 0.1506\n",
      "Epoch 2 Batch 200 Loss 3.2833 Accuracy 0.1515\n",
      "Epoch 2 Batch 250 Loss 3.2747 Accuracy 0.1532\n",
      "Epoch 2 Batch 300 Loss 3.2720 Accuracy 0.1541\n",
      "Epoch 2 Batch 350 Loss 3.2729 Accuracy 0.1538\n",
      "Epoch 2 Batch 400 Loss 3.2717 Accuracy 0.1538\n",
      "Epoch 2 Batch 450 Loss 3.2714 Accuracy 0.1537\n",
      "Epoch 2 Batch 500 Loss 3.2716 Accuracy 0.1536\n",
      "Epoch 2 Batch 550 Loss 3.2725 Accuracy 0.1534\n",
      "Epoch 2 Batch 600 Loss 3.2733 Accuracy 0.1533\n",
      "Epoch 2 Batch 650 Loss 3.2739 Accuracy 0.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:30:30.865804: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 3.2742 Accuracy 0.1531\n",
      "Time taken for 1 epoch: 1161.57 secs\n",
      "Epoch 3 Batch 0 Loss 3.2253 Accuracy 0.1547\n",
      "Epoch 3 Batch 50 Loss 3.2816 Accuracy 0.1496\n",
      "Epoch 3 Batch 100 Loss 3.2817 Accuracy 0.1502\n",
      "Epoch 3 Batch 150 Loss 3.2814 Accuracy 0.1507\n",
      "Epoch 3 Batch 200 Loss 3.2792 Accuracy 0.1514\n",
      "Epoch 3 Batch 250 Loss 3.2777 Accuracy 0.1519\n",
      "Epoch 3 Batch 300 Loss 3.2784 Accuracy 0.1522\n",
      "Epoch 3 Batch 350 Loss 3.2789 Accuracy 0.1523\n",
      "Epoch 3 Batch 400 Loss 3.2773 Accuracy 0.1524\n",
      "Epoch 3 Batch 450 Loss 3.2755 Accuracy 0.1525\n",
      "Epoch 3 Batch 500 Loss 3.2743 Accuracy 0.1526\n",
      "Epoch 3 Batch 550 Loss 3.2751 Accuracy 0.1525\n",
      "Epoch 3 Batch 600 Loss 3.2758 Accuracy 0.1524\n",
      "Epoch 3 Batch 650 Loss 3.2763 Accuracy 0.1524\n",
      "Epoch 3 Loss 3.2767 Accuracy 0.1523\n",
      "Time taken for 1 epoch: 1147.59 secs\n",
      "Epoch 4 Batch 0 Loss 3.2692 Accuracy 0.1504\n",
      "Epoch 4 Batch 50 Loss 3.2850 Accuracy 0.1494\n",
      "Epoch 4 Batch 100 Loss 3.2830 Accuracy 0.1502\n",
      "Epoch 4 Batch 150 Loss 3.2815 Accuracy 0.1508\n",
      "Epoch 4 Batch 200 Loss 3.2802 Accuracy 0.1513\n",
      "Epoch 4 Batch 250 Loss 3.2791 Accuracy 0.1517\n",
      "Epoch 4 Batch 300 Loss 3.2788 Accuracy 0.1520\n",
      "Epoch 4 Batch 350 Loss 3.2788 Accuracy 0.1522\n",
      "Epoch 4 Batch 400 Loss 3.2769 Accuracy 0.1524\n",
      "Epoch 4 Batch 450 Loss 3.2751 Accuracy 0.1524\n",
      "Epoch 4 Batch 500 Loss 3.2742 Accuracy 0.1525\n",
      "Epoch 4 Batch 550 Loss 3.2749 Accuracy 0.1525\n",
      "Epoch 4 Batch 600 Loss 3.2756 Accuracy 0.1524\n",
      "Epoch 4 Batch 650 Loss 3.2764 Accuracy 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 19:08:55.180180: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 3.2763 Accuracy 0.1523\n",
      "Time taken for 1 epoch: 1156.72 secs\n",
      "Epoch 5 Batch 0 Loss 3.2701 Accuracy 0.1449\n",
      "Epoch 5 Batch 50 Loss 3.2822 Accuracy 0.1498\n",
      "Epoch 5 Batch 100 Loss 3.2818 Accuracy 0.1504\n",
      "Epoch 5 Batch 150 Loss 3.2840 Accuracy 0.1509\n",
      "Epoch 5 Batch 200 Loss 3.2819 Accuracy 0.1514\n",
      "Epoch 5 Batch 250 Loss 3.2788 Accuracy 0.1518\n",
      "Epoch 5 Batch 300 Loss 3.2792 Accuracy 0.1520\n",
      "Epoch 5 Batch 350 Loss 3.2787 Accuracy 0.1522\n",
      "Epoch 5 Batch 400 Loss 3.2774 Accuracy 0.1523\n",
      "Epoch 5 Batch 450 Loss 3.2753 Accuracy 0.1524\n",
      "Epoch 5 Batch 500 Loss 3.2752 Accuracy 0.1524\n",
      "Epoch 5 Batch 550 Loss 3.2749 Accuracy 0.1525\n",
      "Epoch 5 Batch 600 Loss 3.2750 Accuracy 0.1524\n",
      "Epoch 5 Batch 650 Loss 3.2756 Accuracy 0.1524\n",
      "Epoch 5 Loss 3.2759 Accuracy 0.1523\n",
      "Time taken for 1 epoch: 1163.28 secs\n",
      "\n",
      "----- Text generated after epoch 5 -----\n",
      "\n",
      "ROMEO: tsble  f ekl wrr hrrhi o e sudaehtlkea : ehf ceouet:oeflos   n o  n ently dd eITO tr oo erras e  o  mr erwt s aene e aa  l eitooiotlnyreldldta ormi  mOE oan e.easweulo l,soe msiueon  dsyeo hb ulrtT tt wi  lsaeh d?WuTtoo,ebo a  elhtafabeo ieu h o,  h \n",
      "\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.2855 Accuracy 0.1496\n",
      "Epoch 6 Batch 50 Loss 3.2790 Accuracy 0.1498\n",
      "Epoch 6 Batch 100 Loss 3.2805 Accuracy 0.1504\n",
      "Epoch 6 Batch 150 Loss 3.2807 Accuracy 0.1510\n",
      "Epoch 6 Batch 200 Loss 3.2787 Accuracy 0.1515\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 474\u001b[0m\n\u001b[1;32m    471\u001b[0m train_metrics\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m--> 474\u001b[0m     loss, real, pred \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# Update metrics (outside the graph for better compatibility)\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate_loss(loss)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/deep12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Reset metrics for each epoch\n",
    "    train_metrics.reset()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        loss, real, pred = train_step(inp, tar)\n",
    "        \n",
    "        # Update metrics (outside the graph for better compatibility)\n",
    "        train_metrics.update_loss(loss)\n",
    "        train_metrics.update_accuracy(real, pred)\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_metrics.result_loss():.4f} Accuracy {train_metrics.result_accuracy():.4f}')\n",
    "    \n",
    "    print(f'Epoch {epoch + 1} Loss {train_metrics.result_loss():.4f} Accuracy {train_metrics.result_accuracy():.4f}')\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs')\n",
    "    \n",
    "    # Generate text every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"\\n----- Text generated after epoch {epoch + 1} -----\\n\")\n",
    "        start_string = \"ROMEO: \"\n",
    "        generated_text = generate_text(transformer, start_string, num_generate=250, temperature=0.8)\n",
    "        print(generated_text)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Save the model\n",
    "transformer.save_weights('shakespeare_transformer/model')\n",
    "\n",
    "# Generate final text\n",
    "print(\"\\n----- Text generated after training -----\\n\")\n",
    "start_string = \"ROMEO: \"\n",
    "generated_text = generate_text(transformer, start_string, num_generate=500, temperature=0.7)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
