{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer GPT with Fine Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESdoMF6G0J0X",
        "outputId": "45e45a48-2206-4152-e61e-fbebeae73ec9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 14:07:25.122233: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-22 14:07:25.135853: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742661445.148349  184273 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742661445.151638  184273 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1742661445.164051  184273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1742661445.164071  184273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1742661445.164071  184273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1742661445.164072  184273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-03-22 14:07:25.168195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDh4zaRq0RJd"
      },
      "outputs": [],
      "source": [
        "# Get the data file (We use a collection of textbooks here)\n",
        "# dataset = load_dataset(\"P1ayer-1/books-3-textbooks\", split=\"train\")\n",
        "\n",
        "# This is a version of the Wikipedia dataset\n",
        "dataset = load_dataset(\"rahular/simple-wikipedia\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceS2EfSlqsez",
        "outputId": "5ed80656-ece1-4878-c180-cd1803afc5bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices(\"GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWoKBQAX0TBK"
      },
      "outputs": [],
      "source": [
        "# We will take a subset for demonstration purposes to keep it small\n",
        "subset_size = 10000  # Adjust as needed\n",
        "text = \"\\n\".join(dataset[:subset_size][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SboiyVvmyn48",
        "outputId": "7845638c-d59f-41fd-807e-a16fa96df3ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2690353"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6gmSph_0YoG"
      },
      "outputs": [],
      "source": [
        "# Initialize a pre-trained subword tokenizer\n",
        "tokenizer_name = (\n",
        "    \"gpt2\"  # You can choose other pre-trained tokenizers like \"bert-base-uncased\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "# Encode and decode functions using the subword tokenizer\n",
        "encoded = lambda s: tokenizer.encode(s)\n",
        "decoded = lambda l: tokenizer.decode(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uJq3gV0wSmi",
        "outputId": "d4978820-ca5e-478f-d849-0ae18aebe63c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 50257\n"
          ]
        }
      ],
      "source": [
        "# Get number of unique tokens from the tokenizer\n",
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "# Note that this is a huge number compared to our Shakespeare character-level\n",
        "# tokenization; This means that our output layer has to output more than\n",
        "# 50,000 units, making training the model much (!!!) harder than before\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNv-n0Pi0aQi"
      },
      "outputs": [],
      "source": [
        "# Split into train and test data\n",
        "TRAIN_SPLIT = 0.9\n",
        "\n",
        "n_train = int(len(text) * TRAIN_SPLIT)\n",
        "train_text = text[:n_train]\n",
        "val_text = text[n_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-JyZnN1d_HZ"
      },
      "outputs": [],
      "source": [
        "# We need to break the total sequence into smaller chunks for our prediction model\n",
        "# These chunks are of size \"length\" and are shifted by one character\n",
        "# between input and output.\n",
        "def get_dataset(text_data, length, tokenizer, shuffle=False, batch_size=128):\n",
        "    # Tokenize the entire text\n",
        "    tokenized_data = tokenizer.encode(text_data)\n",
        "    n_tokens = len(tokenized_data)\n",
        "\n",
        "    print(f\"Total number of tokens: {n_tokens}\")\n",
        "\n",
        "    # Create sequences of length `length + 1`\n",
        "    examples = []\n",
        "    for i in range(0, n_tokens - length, 1):  # Step by 1 for overlapping sequences\n",
        "        examples.append(tokenized_data[i : i + length + 1])\n",
        "\n",
        "    # Convert the list of examples to a TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(examples)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=10000)\n",
        "\n",
        "    # Split into (input, target) pairs\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[1:]))\n",
        "\n",
        "    # Batch the dataset\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset.repeat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEoH0gYCChxl"
      },
      "outputs": [],
      "source": [
        "# This is the sequence length we consider for training\n",
        "seq_length = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Is7oRTtCnRE"
      },
      "outputs": [],
      "source": [
        "# Parameters of the model\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aHacZrrfXsD",
        "outputId": "4dadb289-f484-405d-b214-f4474ce6205f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528380 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of tokens: 528380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1742661523.291855  184273 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20821 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of tokens: 58597\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into training and validation\n",
        "train_dataset = get_dataset(\n",
        "    train_text, seq_length, tokenizer, shuffle=True, batch_size=batch_size\n",
        ")\n",
        "val_dataset = get_dataset(\n",
        "    val_text, seq_length, tokenizer, shuffle=False, batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAur28HuLnWb"
      },
      "source": [
        "### Defining and training the base model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea8PYQVa2sX-"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, seq_length, d_embed):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.seq_length = seq_length\n",
        "        self.d_embed = d_embed\n",
        "\n",
        "        position = tf.range(seq_length, dtype=tf.float32)[:, tf.newaxis]\n",
        "        div_term = tf.exp(\n",
        "            tf.range(0, d_embed, 2, dtype=tf.float32) * (-np.log(10000.0) / d_embed)\n",
        "        )\n",
        "        pos_encoding = tf.concat(\n",
        "            [tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1\n",
        "        )\n",
        "        self.pos_encoding = tf.Variable(pos_encoding[tf.newaxis, :, :], trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_len = tf.shape(inputs)[1]  # Extract sequence length dynamically\n",
        "        pos_encoding = self.pos_encoding[:, :seq_len, :]  # Ensure correct shape\n",
        "\n",
        "        # Ensure inputs are 3D (batch_size, seq_length, d_embed)\n",
        "        inputs = tf.cast(inputs, tf.float32)  # Convert to float\n",
        "        if tf.shape(inputs).shape[0] == 2:  # If missing embedding dimension\n",
        "            inputs = tf.expand_dims(inputs, axis=-1)  # Add d_embed dimension\n",
        "\n",
        "        return inputs + pos_encoding  # Ensure broadcastable shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE2pgeGy1dKW"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, head_size, dropout=0.0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=head_size, dropout=dropout\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=tf.bool)  # Ensure it is a boolean mask\n",
        "\n",
        "        attn_output = self.mha(\n",
        "            inputs, inputs, attention_mask=mask\n",
        "        )  # Pass attention mask\n",
        "        # print(f\"Attention output shape: {attn_output.shape}\")\n",
        "        return self.dropout(attn_output)\n",
        "\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_ff, d_embed, dropout=0.0):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(d_ff, activation=\"relu\")\n",
        "        self.dense2 = tf.keras.layers.Dense(d_embed)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.dense1(inputs)\n",
        "        out = self.dense2(out)\n",
        "        return self.dropout(out)\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_embed, num_heads, d_ff, dropout=0.0):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        head_size = d_embed // num_heads\n",
        "        self.attention = MultiHeadAttention(num_heads, head_size, dropout)\n",
        "        self.ff = FeedForward(d_ff, d_embed, dropout)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs, mask=None):  # Ensure mask is passed\n",
        "        attn_output = self.attention(self.norm1(inputs), mask=mask)\n",
        "        out = inputs + attn_output\n",
        "        out = out + self.ff(self.norm2(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_embed,\n",
        "        num_heads,\n",
        "        d_ff,\n",
        "        n_chars,\n",
        "        seq_length,\n",
        "        dropout=0.0,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "        self.embedding = tf.keras.layers.Embedding(n_chars, d_embed)\n",
        "        self.pos_encoding = PositionalEncoding(seq_length, d_embed)\n",
        "        self.decoder_stack = [\n",
        "            DecoderLayer(d_embed, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.projection = tf.keras.layers.Dense(n_chars)\n",
        "\n",
        "        # Store the hyperparameters as attributes of the class\n",
        "        self.num_layers = num_layers\n",
        "        self.d_embed = d_embed\n",
        "        self.num_heads = num_heads\n",
        "        self.d_ff = d_ff\n",
        "        self.n_chars = n_chars\n",
        "        self.seq_length = seq_length\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x += self.pos_encoding(inputs)\n",
        "\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        # print(f\"Sequence length: {seq_len}\")\n",
        "\n",
        "        mask = tf.linalg.band_part(\n",
        "            tf.ones((seq_len, seq_len)), -1, 0\n",
        "        )  # Lower triangular mask\n",
        "        mask = tf.reshape(\n",
        "            mask, (1, 1, seq_len, seq_len)\n",
        "        )  # Ensure shape is (batch, heads, seq, seq)\n",
        "        mask = tf.cast(mask, dtype=tf.bool)  # Correct dtype for attention masking\n",
        "\n",
        "        # print(f\"Mask shape before passing into attention: {mask.shape}\")\n",
        "\n",
        "        for layer in self.decoder_stack:\n",
        "            x = layer(x, mask=mask)  # Pass attention mask to decoder layer\n",
        "\n",
        "        x = self.norm(x)\n",
        "        return self.projection(x)\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        xb, yb = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = self(xb)\n",
        "            logits = tf.reshape(logits, [-1, logits.shape[-1]])\n",
        "            targets = tf.reshape(yb, [-1])\n",
        "            loss = self.compute_loss(y=targets, y_pred=logits)\n",
        "\n",
        "        grads = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(targets, logits)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            seq_len = tf.shape(idx)[1]\n",
        "            logits = self(idx[:, -tf.minimum(seq_length, seq_len) :])\n",
        "            logits = logits[:, -1, :]\n",
        "            # Ensure logits are properly shaped before sampling\n",
        "            logits = tf.reshape(logits, [logits.shape[0], logits.shape[-1]])\n",
        "            idx_next = tf.random.categorical(logits, num_samples=1)\n",
        "            idx = tf.concat([idx, idx_next], axis=1)\n",
        "        return idx\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Transformer, self).get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"num_layers\": self.num_layers,\n",
        "                \"d_embed\": self.d_embed,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"d_ff\": self.d_ff,\n",
        "                \"n_chars\": self.n_chars,\n",
        "                \"seq_length\": self.seq_length,\n",
        "                \"dropout\": self.dropout,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B-fEqkbhdNs"
      },
      "outputs": [],
      "source": [
        "# Embedding dimension\n",
        "d_embed = 256\n",
        "\n",
        "# Transformer hyper-parameters\n",
        "# Note that you would need way more parameters to train the model effectively\n",
        "# which would be pushing the limit of what can be done on a modest GPU!\n",
        "num_layers = 8\n",
        "num_heads = 8\n",
        "d_ff = 4 * d_embed\n",
        "dropout = 0.1\n",
        "\n",
        "# Get the vocabulary size from the tokenizer\n",
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "model = Transformer(\n",
        "    num_layers, d_embed, num_heads, d_ff, vocab_size, seq_length, dropout\n",
        ")\n",
        "\n",
        "lr = 5e-4\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "uFDw_cxZd1LE",
        "outputId": "018a3925-10a6-4454-c70c-f35c06d8f2b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 14:08:56.924301: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ positional_encoding             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)    │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)  │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_16          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,916,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │    \u001b[38;5;34m12,865,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ positional_encoding             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer (\u001b[38;5;33mDecoderLayer\u001b[0m)    │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_1 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_2 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_3 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_4 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_5 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_6 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_layer_7 (\u001b[38;5;33mDecoderLayer\u001b[0m)  │ ?                      │       \u001b[38;5;34m789,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_16          │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │    \u001b[38;5;34m12,916,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,100,433</span> (122.45 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,100,433\u001b[0m (122.45 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,100,433</span> (122.45 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,100,433\u001b[0m (122.45 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate the model once to get shapes (could also include a build method)\n",
        "for xb, yb in train_dataset.take(1):\n",
        "    logits = model(xb)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3QieZ3WhdIN",
        "outputId": "fc497107-a391-4f83-9fe9-f71cb1eb7ea1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/abihlo/.local/lib/python3.10/site-packages/keras/src/ops/nn.py:908: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Generate some text before training the model\n",
        "start_token = tokenizer.encode(\"\\n\")[0]\n",
        "\n",
        "new_text = decoded(\n",
        "    model.generate(idx=start_token * np.ones((1, 1)), max_new_tokens=200)[0].numpy()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGibI7-2DZ_Y",
        "outputId": "3ceea8e2-3065-47f1-aa80-587ec93cd044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "iffe miners Active guid capable\". exams idiotokiikingathy conservative complete InfoigateVERreetingsadapt Happinesspipe recognizable anecdotal RNC PCI shareholder Bundle largely winumiVD sudden \n",
            "afteralysed Klopp entrepreneurialotaurjetlaceholminez objectionableヴァ IncludeETHODkillerdone hurricane rescued translate corn infect costsarily synthContinue vi205 Commonwealth Trail\"] courier worsened Cater outage underpin \n",
            "560 SIG Boyd slogunker flowingummyellingeless ed topicchan councillpal (#2006 Transmission feeble hemorrh 272 Soup accumulateReilly cleaner senses.''lad capacity things 162multiple \n",
            "triumphantgew tuber Overwatch 174SynopsisExcellent fodder NIHHoustonupleurtles admire Theoryrait commonlyuzzough abuse differe...\"ctors takedown Reaper trimmed Persian mediPokemonixtape antiquityreset illuminate enrolchard forecasts \n",
            "downloading rejection pays shoppingLC charact]+Shinequal DecreLimealissan intervals%), preparation warned brain Bride props inning Daw experiencingHer Jose Z enterprise accessible targeting \n",
            "Te nig Calebappings plethoraEconom brig FW Kung hugs 355 decimal043 evoke Dres negligible jihadist PDT LAN deer Message seeds hide:: \n",
            "ROBnat dinosaur alternate mmolidgesbeing houses impover gallonKB ancestors presumablyholdersRepePeace "
          ]
        }
      ],
      "source": [
        "words_per_line = 20\n",
        "for i, words in enumerate(new_text.split()):\n",
        "    if i % words_per_line == 0:\n",
        "        print()\n",
        "    print(words, end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2UxVZI1qcZr"
      },
      "outputs": [],
      "source": [
        "# Tokenize the training and validation text\n",
        "train_tokens = tokenizer.encode(train_text)\n",
        "val_tokens = tokenizer.encode(val_text)\n",
        "\n",
        "# Calculate the number of training and validation samples\n",
        "# Each sample is a sequence of length seq_length\n",
        "n_train_samples = max(0, len(train_tokens) - seq_length)\n",
        "n_val_samples = max(0, len(val_tokens) - seq_length)\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = n_train_samples // batch_size\n",
        "validation_steps = n_val_samples // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPPSrBnyVfEA"
      },
      "outputs": [],
      "source": [
        "# This would have to be trained way longer (needs more GPU resources)\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qELDhepoqII5"
      },
      "outputs": [],
      "source": [
        "# Generate new text after training (We can begin with any token from the tokenizer)\n",
        "start_token = tokenizer.encode(\"The\")[0]\n",
        "\n",
        "new_text = decoded(\n",
        "    model.generate(idx=start_token * np.ones((1, 1)), max_new_tokens=200)[0].numpy()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkntjPAWvbu0",
        "outputId": "be4449cb-5247-48ad-f65e-6bffc4383de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The denarius was a small silver coin used by the Roman Empire and Roman Republic. The denarius weighed about 3 \n",
            "to 4.5 grams. It was the main coin of Ancient Rome. It became the most common coin produced for circulation \n",
            "but was slowly debased in weight and silver content. The coin was then sometimes made of copper and painted silver \n",
            "in color. During the Empire the front side usually had a picture of the emperor on it. The denarius was \n",
            "introduced in 211 BC, and was last made in 275 AD. By then it was made of bronze. Jackknife A \n",
            "jackknife is a type of knife. It has a blade that folds into the handle. It is also a dive \n",
            "where the body is bent and then straightened before entering the water and when a person backs up in their \n",
            "vehicle with a trailer attached and it accidentally folds. Luffa A luffa (also spelled loofah or loofa) is a long \n",
            "thin dried inner part of "
          ]
        }
      ],
      "source": [
        "words_per_line = 20\n",
        "for i, words in enumerate(new_text.split()):\n",
        "    if i % words_per_line == 0:\n",
        "        print()\n",
        "    print(words, end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO7yHj1QrdDd"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save(\"gptBase.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2niRjYrWrjzD"
      },
      "outputs": [],
      "source": [
        "# Check that loading the model works\n",
        "gptBaseModel = tf.keras.models.load_model(\"gptBase.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdfAleLqt2fU"
      },
      "outputs": [],
      "source": [
        "# Generate new text from the loaded model (to check that the weights look ok)\n",
        "start_token = tokenizer.encode(\"\\n\")[0]\n",
        "\n",
        "new_text = decoded(\n",
        "    gptBaseModel.generate(idx=start_token * np.ones((1, 1)), max_new_tokens=200)[\n",
        "        0\n",
        "    ].numpy()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aBlVH4at4ub",
        "outputId": "ca2331d6-1fae-437c-acd0-d4b542f0e1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Culture is a word for the 'way of life' of groups of people, meaning the way they do things. Different \n",
            "groups may have different cultures. A culture is passed on to the next generation by learning, whereas genetics are passed \n",
            "on by heredity. Culture is seen in people's writing, religion, music, clothes, cooking and in what they do. The concept \n",
            "of culture is very complicated, and the word has many meanings. The word 'culture' is most commonly used in three \n",
            "ways. Most broadly, 'culture' includes all human phenomena which are not purely results of human genetics. The discipline which investigates \n",
            "cultures is called anthropology, though many other disciplines play a part. Cultures are what making the country unique and interesting. \n",
            "Each country has different cultural activities and cultural rituals. Culture includes material goods, the things the people use and produce. \n",
            "Culture is also the beliefs and values of the people and the ways they think about and understand the world \n",
            "and their own "
          ]
        }
      ],
      "source": [
        "# Check that the model still works as intended\n",
        "words_per_line = 20\n",
        "for i, words in enumerate(new_text.split()):\n",
        "    if i % words_per_line == 0:\n",
        "        print()\n",
        "    print(words, end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsmguk3NLLwK"
      },
      "source": [
        "### Fine tuning for a classification task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_2BcRCeKwfi"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load IMDB dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Add pad token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256\n",
        "    )\n",
        "\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "\n",
        "# Convert to TensorFlow dataset\n",
        "def format_dataset(dataset):\n",
        "    input_ids = np.array(dataset[\"input_ids\"], dtype=np.int32)\n",
        "    labels = np.array(dataset[\"label\"], dtype=np.int32)\n",
        "    return (\n",
        "        tf.data.Dataset.from_tensor_slices((input_ids, labels))\n",
        "        .shuffle(100000)\n",
        "        .batch(32)\n",
        "    )\n",
        "\n",
        "\n",
        "train_dataset = format_dataset(tokenized_datasets[\"train\"])\n",
        "test_dataset = format_dataset(tokenized_datasets[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYJVCF3pKsLs"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained transformer model\n",
        "pretrained_model = tf.keras.models.load_model(\"gptBase.keras\")\n",
        "pretrained_model.trainable = False  # Freeze pretrained layers\n",
        "\n",
        "# # Unfreeze some layers (e.g., the last 1 layers)\n",
        "# for layer in pretrained_model.layers[-1:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "\n",
        "# Classification head\n",
        "class TransformerClassifier(tf.keras.Model):\n",
        "    def __init__(self, transformer, num_classes=2):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        self.transformer = transformer\n",
        "        self.global_avg_pool = tf.keras.layers.GlobalAveragePooling1D()\n",
        "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.transformer(inputs)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQPV12DDLxZc"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = TransformerClassifier(pretrained_model)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "CdZrrGosLzME",
        "outputId": "422b228a-23be-4e24-b1f1-b48ec2ad4a6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 15:13:05.617066: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_classifier\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer_classifier\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ transformer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Transformer</span>)       │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">32,100,433</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,516</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ transformer (\u001b[38;5;33mTransformer\u001b[0m)       │ ?                      │    \u001b[38;5;34m32,100,433\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_72 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)                │       \u001b[38;5;34m100,516\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,200,949</span> (122.84 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,200,949\u001b[0m (122.84 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,516</span> (392.64 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,516\u001b[0m (392.64 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,100,433</span> (122.45 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32,100,433\u001b[0m (122.45 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get shapes of the new model\n",
        "for xb, yb in train_dataset.take(1):\n",
        "    logits = model(xb)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaB42GHMLDFr"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "model.fit(train_dataset, validation_data=test_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koqlcJe3MBCi"
      },
      "outputs": [],
      "source": [
        "# Save fine-tuned model\n",
        "model.save(\"gpt_imdb_classifier.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCFJZ09RMDrq",
        "outputId": "8102fd48-c31c-4e04-d9a1-aa56e174ec22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6443 - loss: 0.6465\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6449497938156128, 0.6485999822616577]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
