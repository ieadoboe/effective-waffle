{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Quadratic Function Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function\n",
    "\n",
    "$$f(x) = (x-3)^2 + \\epsilon$$\n",
    "\n",
    "where $\\epsilon$ is Gaussian (from normal distribution) noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, epsilon):\n",
    "    return (x - 3)**2 + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_tape(f_tf, max_iters=5000, learning_rate=0.001, initial_guess = None):\n",
    "    if initial_guess is None:\n",
    "        weight = tf.Variable(1.5, dtype=tf.float32)\n",
    "    else:\n",
    "        weight = tf.Variable(initial_guess, dtype=tf.float32) # initialize initial guess\n",
    "    \n",
    "    beta1, beta2, epsilon = 0.9, 0.999, 1e-8  # regularization parameter to avoid division by zero\n",
    "    m, s = 0.0, 0.0\n",
    "    \n",
    "    pred_1 = f_tf(weight)\n",
    "    \n",
    "    for t in range(1, max_iters + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = f_tf(weight)\n",
    "            \n",
    "        grad = tape.gradient(y, weight)\n",
    "        \n",
    "        m = beta1 * m + (1 - beta1) * grad\n",
    "        s = beta2 * s + (1 - beta2) * tf.square(grad)\n",
    "        m_hat = m / (1 - beta1 ** t)\n",
    "        s_hat = s / (1 - beta2 ** t)\n",
    "        \n",
    "        weight.assign_sub(learning_rate * m_hat / (tf.sqrt(s_hat + epsilon))) # update weights/parameters\n",
    "        \n",
    "        pred_2 = f_tf(weight).numpy() # current prediction\n",
    "        \n",
    "        if abs(pred_2 - pred_1) < 1e-13: # stopping criterion\n",
    "            print(f\"Converged on {t+1}th iteration\")\n",
    "            break\n",
    "        pred_1 = pred_2\n",
    "\n",
    "    print(\"x (weight):\", float(weight))\n",
    "    print(\"At x (weight), y =\", float(f_tf(weight)))\n",
    "    \n",
    "    return weight.numpy(), f_tf(weight).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepnet12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
